{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQjsbJinq6CH",
        "outputId": "c861bf6b-3a9b-4d71-ffda-8a50380d759a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bigtree\n",
            "  Downloading bigtree-0.16.4-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/73.6 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m997.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bigtree\n",
            "Successfully installed bigtree-0.16.4\n"
          ]
        }
      ],
      "source": [
        "pip install bigtree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3Klsa7VPwEde"
      },
      "outputs": [],
      "source": [
        "# installing the required packages\n",
        "import numpy as np\n",
        "from scipy.stats import gaussian_kde\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KernelDensity\n",
        "import pandas as pd\n",
        "from bigtree import dataframe_to_tree\n",
        "from scipy.optimize import minimize\n",
        "from scipy.signal import find_peaks\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4RCiUwQfwOgv"
      },
      "outputs": [],
      "source": [
        "# Load the Iris dataset\n",
        "x, y = load_iris(return_X_y=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x data instance:-\", len(x),\"\\n\",x[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi83dqLzM2YO",
        "outputId": "5fa961e9-93e3-434d-8c55-803b9a938f37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data instance:- 150 \n",
            " [[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"y is\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvmKHrVEM4IM",
        "outputId": "edc2d772-3d8a-4ec0-dd61-579f12f42884"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y is [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Qwa7sO-Z1j0P"
      },
      "outputs": [],
      "source": [
        "# for Class 0\n",
        "x0=x[y==0]\n",
        "y0=y[y==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ojMrvwWnKCXU"
      },
      "outputs": [],
      "source": [
        "# for Class 1\n",
        "x1=x[y==1]\n",
        "y1=y[y==1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8Y3IdIPKRYUj"
      },
      "outputs": [],
      "source": [
        "# for Class 2\n",
        "x2=x[y==2]\n",
        "y2=y[y==2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x0[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMee4x71QJ8s",
        "outputId": "9a920f49-5e42-435a-c94f-8bfab63594a5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTibLKxm87uQ",
        "outputId": "f483dc02-e5c0-4700-c3ea-aa4933f5bfbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "x0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9tcJZPE82xZ",
        "outputId": "9867e07c-13ce-4cba-e8c9-17f4aebdddc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "y0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kJ5TCT_wrAe2"
      },
      "outputs": [],
      "source": [
        "# taking default values as given in the research paper\n",
        "gmm=0.05\n",
        "alp=0.5\n",
        "beta=0.02\n",
        "nu=0.05\n",
        "max_depth=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "crn2LA97VSLY"
      },
      "outputs": [],
      "source": [
        "def all_elements_same(items):\n",
        "    return len(set(items)) == 1\n",
        "\n",
        "# bandwidth calculating function\n",
        "def h_t(dt):\n",
        "    if(all_elements_same(dt)):\n",
        "       return 0.9*0.001*((len(dt))**(-0.2))\n",
        "    dte=dt.copy()\n",
        "    dte.sort()\n",
        "    Q1 = np.percentile(dte, 25)\n",
        "    Q3 = np.percentile(dte, 75)\n",
        "    IQR = Q3 - Q1\n",
        "    std_dev = np.std(dte)\n",
        "    if(float(IQR)!=0.0) :\n",
        "     return 0.9*(min(std_dev,IQR/1.34))*((len(dte))**(-0.2))\n",
        "    else :\n",
        "     return 0.9*std_dev*((len(dte))**(-0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HBTUENEBsssf"
      },
      "outputs": [],
      "source": [
        "def split_data(dt):\n",
        "  heights = dt.reshape(-1, 1)\n",
        "\n",
        "  # Create a KDE estimator\n",
        "  kde = KernelDensity(kernel='gaussian', bandwidth=h_t(dt)).fit(heights)\n",
        "\n",
        "  # Generate points for density estimation\n",
        "  x_len = np.linspace(min(heights)-1,max(heights)+1, 1000).reshape(-1, 1)\n",
        "\n",
        "  # Estimate the density\n",
        "  log_dens = kde.score_samples(x_len)\n",
        "  dens = np.exp(log_dens)\n",
        "\n",
        "\n",
        "  peaks, _ = find_peaks(dens)\n",
        "  minima, _ = find_peaks(-dens)\n",
        "  dte=dt.copy()\n",
        "  maxima=peaks.copy()\n",
        "  dte.sort()\n",
        "  for i in range(len(minima)):\n",
        "    peaks=np.append(peaks,minima[i])\n",
        "  mx_mn=[]\n",
        "  peaks.sort()\n",
        "  for i in range(len(peaks)):\n",
        "    mx_mn.append([peaks[i],dens[peaks[i]]])\n",
        "  mx_mn=np.array(mx_mn)\n",
        "  mx=-99999999\n",
        "  mn=999999999\n",
        "  new_dte=[]\n",
        "  for  i in range(len(dte)): # removing data points whose kde values are below gamma * max_peak\n",
        "    if(np.exp(kde.score_samples([[dte[i]]]))[0]<gmm*max(mx_mn[:,1])):\n",
        "     continue\n",
        "    else :\n",
        "      mx=max(mx,dte[i])\n",
        "      mn=min(mn,dte[i])\n",
        "      new_dte.append([dte[i],np.exp(kde.score_samples([[dte[i]]]))[0]])\n",
        "\n",
        "  # creating a limits array based on condition given in research paper\n",
        "  limits=[]\n",
        "  limits.append(mn)\n",
        "  for i in range(len(peaks)):\n",
        "    if(i%2==1):\n",
        "      if(mx_mn[i][1]<=alp*min(mx_mn[i-1][1],mx_mn[i+1][1])):\n",
        "        limits.append(x_len[int(mx_mn[i][0])][0])\n",
        "  limits.append(mx)\n",
        "\n",
        "  splits=[]\n",
        "  n_dash=len(dt)*(1/(max(dt)-min(dt)))\n",
        "  impurity=0.0\n",
        "\n",
        "  # creating splits from limits\n",
        "  for i in range(1,len(limits)):\n",
        "    mxx=-99999999.9\n",
        "    mnn=999999999.9\n",
        "    n=0\n",
        "    for j in range(len(new_dte)):\n",
        "      if(new_dte[j][0]>=limits[i-1] and new_dte[j][0]<=limits[i]):\n",
        "         mxx=max(mxx,new_dte[j][0])\n",
        "         mnn=min(mnn,new_dte[j][0])\n",
        "         n+=1\n",
        "    impurity+=(n*n_dash*(mxx-mnn))/(n+n_dash*(mxx-mnn)) # calculating the impurity\n",
        "    splits.append([mnn,mxx])\n",
        "  if(len(splits)==0):\n",
        "    if(limits[0]==limits[1]):\n",
        "      return [[]],99999999\n",
        "    else :\n",
        "      return [limits],(len(new_dte)*n_dash*(limits[1]-limits[0]))/(len(new_dte)+n_dash*(limits[1]-limits[0]))\n",
        "  else :\n",
        "    new_splits = []\n",
        "    for i in range(len(splits)):\n",
        "      if(splits[i][0]!=splits[i][1]):\n",
        "        new_splits.append(splits[i])\n",
        "\n",
        "    splits = new_splits\n",
        "    return splits,impurity # returning the splits containing array of (Li, Ri) and the impurity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def impurity_same(impty):\n",
        "  item=[]\n",
        "  for i in impty:\n",
        "     item.append(impty[i])\n",
        "  return all_elements_same(item)"
      ],
      "metadata": {
        "id": "b3jmatBXs9ZC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_sl(s): # checks the depth of the oc tree\n",
        "  c=0\n",
        "  for i in range(len(s)):\n",
        "    if(s[i]==\"/\"):\n",
        "      c+=1\n",
        "  return c"
      ],
      "metadata": {
        "id": "xVAEiCgW87nv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4GgSFo-Mx0d5"
      },
      "outputs": [],
      "source": [
        "dft = pd.DataFrame( [],columns=[\"PATH\",\"ATR\",\"LR\"]) # creating a dataframe which will be converted into oc Tree\n",
        "\n",
        "# taking 2 d array of data and variables for storing paths for future work of OC Tree ( fcc )\n",
        "def fit(data,fcc,k,s,dft):\n",
        " data = np.array(data) if isinstance(data, list) else data\n",
        "\n",
        " if(fcc==0):\n",
        "  dft.loc[len(dft.index)] =[s, None,None]\n",
        "  fit(data,fcc+1,k,s,dft)\n",
        " else :\n",
        "  if(fcc!=1):\n",
        "    if(len(data)<=k or check_sl(dft.iloc[len(dft.index)-1]['PATH'])>=max_depth): # local & Global Stopping Conditions\n",
        "     return\n",
        "    else:\n",
        "      dict={}\n",
        "      impurity={}\n",
        "      for j in range(len(data[0])):\n",
        "        dict[j],impurity[j]=split_data(data[:,j]) # calculating splits and impurity for each feature\n",
        "      mn=9999999\n",
        "      key=0\n",
        "      if(impurity_same(impurity)): # taking best feature for splits based on impurity\n",
        "         c=check_sl(dft.iloc[len(dft.index)-1]['PATH'])\n",
        "         arr={}\n",
        "         atr_min_cnt=99999\n",
        "         for j in range(len(data[0])):\n",
        "          arr[j]=0\n",
        "         for i in range(len(dft.index)-1,len(dft.index)-1-c,-1):\n",
        "           arr[(dft.iloc[i]['ATR'])]+=1\n",
        "         for j in arr:\n",
        "           if(arr[j]<atr_min_cnt):\n",
        "            atr_min_cnt=arr[j]\n",
        "            key=j\n",
        "\n",
        "      else :\n",
        "       for j in impurity:\n",
        "            if(impurity[j]<mn):\n",
        "              mn=impurity[j]\n",
        "              key=j\n",
        "      split=dict[key]\n",
        "      dte =[]\n",
        "      for i in range(len(split)):\n",
        "        chi=[]\n",
        "        for j in range(len(data)):\n",
        "          if( data[j][key]>=split[i][0] and data[j][key]<=split[i][1]):\n",
        "               chi.append(data[j])\n",
        "        dte.append(chi)\n",
        "      for i in range(len(dte)):\n",
        "        s+='/'+str(fcc)\n",
        "        val = split[i]\n",
        "\n",
        "        dft.loc[len(dft.index)] = [s,key,val] # storing path , feature, splits limit\n",
        "\n",
        "        fit(dte[i],fcc+1,k,s,dft) # making the Recursive Call for the next node\n",
        "        s=s[:-2]\n",
        "\n",
        "  else :\n",
        "      dict={}\n",
        "      impurity={}\n",
        "      for j in range(len(data[0])):\n",
        "        dict[j],impurity[j]=split_data(data[:,j])\n",
        "      mn=9999999\n",
        "      key=0\n",
        "\n",
        "      for j in impurity:\n",
        "          if(impurity[j]<mn):\n",
        "            mn=impurity[j]\n",
        "            key=j\n",
        "      split=m=np.array(dict[(key)])\n",
        "\n",
        "      dte =[]\n",
        "\n",
        "      for i in range(len(split)):\n",
        "        chi=[]\n",
        "        for j in range(len(data)):\n",
        "          if( data[j][key]>=split[i][0] and data[j][key]<=split[i][1]):\n",
        "               chi.append(data[j])\n",
        "        dte.append(chi)\n",
        "\n",
        "\n",
        "      for i in range(len(dte)):\n",
        "        s+='/'+str(fcc)\n",
        "        val = split[i]\n",
        "\n",
        "        dft.loc[len(dft.index)] = [s,key,val]\n",
        "        fit(dte[i],fcc+1,k,s,dft)\n",
        "        s=s[:-2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fyejOVIRJMcg"
      },
      "outputs": [],
      "source": [
        "fit(x0,0,int(beta*len(x0)),'0',dft) # storing the oc Tree into dataframe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ensmEjQuTbOC",
        "outputId": "09ca5d8d-652c-4fc1-c232-f9213a9c581e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        PATH   ATR          LR\n",
            "0          0  None        None\n",
            "1        0/1     3  [0.1, 0.4]\n",
            "2      0/1/2     1  [2.9, 4.4]\n",
            "3    0/1/2/3     2  [1.0, 1.7]\n",
            "4  0/1/2/3/4     0  [4.3, 5.8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inc5OVdiBfCk",
        "outputId": "0a3b83f9-8358-4ab1-9475-9d239eb48a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [ATR=None, LR=None]\n",
            "└── 1 [ATR=3, LR=[0.1 0.4]]\n",
            "    └── 2 [ATR=1, LR=[2.9, 4.4]]\n",
            "        └── 3 [ATR=2, LR=[1.0, 1.7]]\n",
            "            └── 4 [ATR=0, LR=[4.3, 5.8]]\n"
          ]
        }
      ],
      "source": [
        "# Converting dataframe to Tree\n",
        "rooot = dataframe_to_tree(dft)\n",
        "rooot.show(attr_list=[\"PATH\",\"ATR\",\"LR\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function for prediction of class given 1d array\n",
        "def pred(node,dt):\n",
        "    for child in node.children:\n",
        "      if(dt[child.ATR]>=child.LR[0] and dt[child.ATR]<=child.LR[1] ):\n",
        "        pred(child,dt)\n",
        "        if child.children != ():\n",
        "            if(pred(child,dt)):\n",
        "               return \"Yes\"\n",
        "        else :\n",
        "            return \"Yes\"\n",
        "      else :\n",
        "        continue\n",
        "    return \"No\"\n"
      ],
      "metadata": {
        "id": "dqbFiPdkgowP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt=x0[2]"
      ],
      "metadata": {
        "id": "q_aKQ144ivLT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d29DOYkJiyEq",
        "outputId": "dddda0d3-2ba4-4c26-9646-e218350dee20"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.7, 3.2, 1.3, 0.2])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# comparing results with the svdd method"
      ],
      "metadata": {
        "id": "7PSCA8RDVP1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install deep-svdd  # Example, adjust based on actual package/library\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxuEmEJyVaCX",
        "outputId": "cf180da0-669a-4396-d90f-bd3e7f2e2b61"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deep-svdd\n",
            "  Downloading deep_svdd-1.3-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deep-svdd) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deep-svdd) (1.2.2)\n",
            "Collecting tensorflow-gpu>=1.12.0 (from deep-svdd)\n",
            "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conducting Experiments"
      ],
      "metadata": {
        "id": "IG94ke3JRuJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For Class 0"
      ],
      "metadata": {
        "id": "6aMuv6KPRzJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.svm import OneClassSVM  # Assuming SVDD is similar to sklearn's OneClassSVM for demonstration\n",
        "\n",
        "dft0 = pd.DataFrame( [],columns=[\"PATH\",\"ATR\",\"LR\"])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test = train_test_split(x0, test_size=0.2, random_state=42)\n",
        "\n",
        "fit(X_train,0,int(beta*len(X_train)),'0',dft0)\n",
        "rooot0 = dataframe_to_tree(dft0)\n",
        "rooot0.show(attr_list=[\"PATH\",\"ATR\",\"LR\"])\n",
        "\n",
        "# Train SVDD\n",
        "svdd_model = OneClassSVM(kernel='rbf', nu=0.1)  # Nu parameter determines the ratio of outliers\n",
        "svdd_model.fit(X_train)\n",
        "\n",
        "print(\"xtest is\", X_test)\n",
        "# Predictions for SVDD\n",
        "svdd_predictions = svdd_model.predict(X_test)  # SVDD predicts 1 for inliers and -1 for outliers\n",
        "\n",
        "# Convert SVDD predictions to match Simple OC Tree format (1 for target class, -1 for outliers)\n",
        "svdd_predictions = np.where(svdd_predictions == 1, 1, -1)\n",
        "\n",
        "pred_arr = []\n",
        "for i in range(len(X_test)):\n",
        "  if(pred(rooot0, X_test[i]) == \"Yes\"):\n",
        "    pred_arr.append(1)\n",
        "  else:\n",
        "    pred_arr.append(0)\n",
        "\n",
        "print(\"prediction arr\", pred_arr)\n",
        "# Calculate precision and recall for both models\n",
        "oc_tree_precision = precision_score(y_true=np.ones(len(X_test)), y_pred=pred_arr)\n",
        "oc_tree_recall = recall_score(y_true=np.ones(len(X_test)), y_pred=pred_arr)\n",
        "\n",
        "svdd_precision = precision_score(y_true=np.ones(len(X_test)), y_pred=svdd_predictions)\n",
        "svdd_recall = recall_score(y_true=np.ones(len(X_test)), y_pred=svdd_predictions)\n",
        "\n",
        "\n",
        "\n",
        "print(\"OC Tree Precision:\", oc_tree_precision)\n",
        "print(\"OC Tree Recall:\", oc_tree_recall)\n",
        "print(\"SVDD Precision:\", svdd_precision)\n",
        "print(\"SVDD Recall:\", svdd_recall)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "SC8rRtEWVtOb",
        "outputId": "ae3ea92e-20d0-45dd-ba3c-12c599cd3a1d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [ATR=None, LR=None]\n",
            "└── 1 [ATR=3, LR=[0.1 0.3]]\n",
            "xtest is [[4.3 3.  1.1 0.1]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.1 3.8 1.5 0.3]]\n",
            "prediction arr [1, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
            "OC Tree Precision: 1.0\n",
            "OC Tree Recall: 0.9\n",
            "SVDD Precision: 1.0\n",
            "SVDD Recall: 0.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For Class 1"
      ],
      "metadata": {
        "id": "s589toNDR2zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.svm import OneClassSVM  # Assuming SVDD is similar to sklearn's OneClassSVM for demonstration\n",
        "\n",
        "dft1 = pd.DataFrame( [],columns=[\"PATH\",\"ATR\",\"LR\"])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test = train_test_split(x1, test_size=0.2, random_state=42)\n",
        "\n",
        "fit(X_train,0,int(beta*len(X_train)),'0',dft1)\n",
        "rooot1 = dataframe_to_tree(dft1)\n",
        "rooot1.show(attr_list=[\"PATH\",\"ATR\",\"LR\"])\n",
        "\n",
        "# Train SVDD\n",
        "svdd_model = OneClassSVM(kernel='rbf', nu=0.1)  # Nu parameter determines the ratio of outliers\n",
        "svdd_model.fit(X_train)\n",
        "\n",
        "print(\"xtest is\", X_test)\n",
        "# Predictions for SVDD\n",
        "svdd_predictions = svdd_model.predict(X_test)  # SVDD predicts 1 for inliers and -1 for outliers\n",
        "\n",
        "# Convert SVDD predictions to match Simple OC Tree format (1 for target class, -1 for outliers)\n",
        "svdd_predictions = np.where(svdd_predictions == 1, 1, -1)\n",
        "\n",
        "pred_arr = []\n",
        "for i in range(len(X_test)):\n",
        "  if(pred(rooot1, X_test[i]) == \"Yes\"):\n",
        "    pred_arr.append(1)\n",
        "  else:\n",
        "    pred_arr.append(0)\n",
        "\n",
        "print(\"prediction arr\", pred_arr)\n",
        "# Calculate precision and recall for both models\n",
        "oc_tree_precision = precision_score(y_true=np.ones(len(X_test)), y_pred=pred_arr)\n",
        "oc_tree_recall = recall_score(y_true=np.ones(len(X_test)), y_pred=pred_arr)\n",
        "\n",
        "svdd_precision = precision_score(y_true=np.ones(len(X_test)), y_pred=svdd_predictions)\n",
        "svdd_recall = recall_score(y_true=np.ones(len(X_test)), y_pred=svdd_predictions)\n",
        "\n",
        "\n",
        "\n",
        "print(\"OC Tree Precision:\", oc_tree_precision)\n",
        "print(\"OC Tree Recall:\", oc_tree_recall)\n",
        "print(\"SVDD Precision:\", svdd_precision)\n",
        "print(\"SVDD Recall:\", svdd_recall)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Eoa8w160cbrR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "d70f0727-6fc0-46d4-bf61-21557d8156f3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [ATR=None, LR=None]\n",
            "└── 1 [ATR=3, LR=[1.2 1.8]]\n",
            "    └── 2 [ATR=0, LR=[5.2, 7.0]]\n",
            "        └── 3 [ATR=1, LR=[2.2, 3.4]]\n",
            "            └── 4 [ATR=2, LR=[3.6, 5.1]]\n",
            "xtest is [[6.1 2.9 4.7 1.4]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [5.6 2.5 3.9 1.1]]\n",
            "prediction arr [1, 1, 0, 1, 0, 0, 1, 1, 1, 0]\n",
            "OC Tree Precision: 1.0\n",
            "OC Tree Recall: 0.6\n",
            "SVDD Precision: 1.0\n",
            "SVDD Recall: 0.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For Class 2"
      ],
      "metadata": {
        "id": "-dDCAkmdSChb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.svm import OneClassSVM  # Assuming SVDD is similar to sklearn's OneClassSVM for demonstration\n",
        "\n",
        "dft2 = pd.DataFrame( [],columns=[\"PATH\",\"ATR\",\"LR\"])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test = train_test_split(x2, test_size=0.2, random_state=42)\n",
        "\n",
        "fit(X_train,0,int(beta*len(X_train)),'0',dft2)\n",
        "rooot2 = dataframe_to_tree(dft2)\n",
        "rooot2.show(attr_list=[\"PATH\",\"ATR\",\"LR\"])\n",
        "\n",
        "# Train SVDD\n",
        "svdd_model = OneClassSVM(kernel='rbf', nu=0.1)  # Nu parameter determines the ratio of outliers\n",
        "svdd_model.fit(X_train)\n",
        "\n",
        "print(\"xtest is\", X_test)\n",
        "# Predictions for SVDD\n",
        "svdd_predictions = svdd_model.predict(X_test)  # SVDD predicts 1 for inliers and -1 for outliers\n",
        "\n",
        "# Convert SVDD predictions to match Simple OC Tree format (1 for target class, -1 for outliers)\n",
        "svdd_predictions = np.where(svdd_predictions == 1, 1, -1)\n",
        "\n",
        "pred_arr = []\n",
        "for i in range(len(X_test)):\n",
        "  if(pred(rooot2, X_test[i]) == \"Yes\"):\n",
        "    pred_arr.append(1)\n",
        "  else:\n",
        "    pred_arr.append(0)\n",
        "\n",
        "print(\"prediction arr\", pred_arr)\n",
        "# Calculate precision and recall for both models\n",
        "oc_tree_precision = precision_score(y_true=np.ones(len(X_test)), y_pred=pred_arr)\n",
        "oc_tree_recall = recall_score(y_true=np.ones(len(X_test)), y_pred=pred_arr)\n",
        "\n",
        "svdd_precision = precision_score(y_true=np.ones(len(X_test)), y_pred=svdd_predictions)\n",
        "svdd_recall = recall_score(y_true=np.ones(len(X_test)), y_pred=svdd_predictions)\n",
        "\n",
        "\n",
        "\n",
        "print(\"OC Tree Precision:\", oc_tree_precision)\n",
        "print(\"OC Tree Recall:\", oc_tree_recall)\n",
        "print(\"SVDD Precision:\", svdd_precision)\n",
        "print(\"SVDD Recall:\", svdd_recall)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "q-_uX9gTSC43",
        "outputId": "f6fd9222-7525-46cf-dc56-9ab59abbf450"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [ATR=None, LR=None]\n",
            "└── 1 [ATR=0, LR=[5.6 7.9]]\n",
            "    └── 2 [ATR=0, LR=[5.6, 7.9]]\n",
            "        └── 3 [ATR=0, LR=[5.6, 7.9]]\n",
            "            └── 4 [ATR=0, LR=[5.6, 7.9]]\n",
            "xtest is [[5.7 2.5 5.  2. ]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.  2.2 5.  1.5]]\n",
            "prediction arr [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "OC Tree Precision: 1.0\n",
            "OC Tree Recall: 1.0\n",
            "SVDD Precision: 1.0\n",
            "SVDD Recall: 0.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}